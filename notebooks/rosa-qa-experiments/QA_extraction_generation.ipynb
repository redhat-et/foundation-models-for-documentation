{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d838b24-a37f-47f4-bcf7-8ea4d8027086",
   "metadata": {},
   "source": [
    "# Question-Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2591cdd3-64be-4564-911e-799b0a474019",
   "metadata": {},
   "source": [
    "Question Answering (QA) system is a sub-field of Natural Language Processing (NLP) that deals with automating the task of answering questions posed in natural language. It involves processing the input question, retrieving relevant information from a database or a corpus, and presenting a concise answer to the user. QA systems can be broadly classified into two types: Open Domain and Closed Domain. Open Domain QA systems are designed to answer any type of question, without being restricted to a specific topic or domain. Closed Domain QA systems, on the other hand, are designed to answer questions within a specific domain or category of knowledge, such as medicine, law, or geography. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7911705-fed6-454a-af82-bacf7880c0f3",
   "metadata": {},
   "source": [
    "## Extractive QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af564075-35d0-4c61-b713-b8867193d678",
   "metadata": {},
   "source": [
    "Extractive QA systems work by identifying and extracting a relevant answer from a large corpus of text. The answer is usually a span of text that directly answers the question. The system uses techniques such as information retrieval, named entity recognition, and co-reference resolution to extract the most relevant answer. Extractive QA systems are designed to work well when the answer is present in the text and can be accurately extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039398c6-7c49-4cb4-88d2-274405a60a07",
   "metadata": {},
   "source": [
    "Lets start by creating a corpus of text from the pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "148a99ac-5f54-4cc6-9c8b-d65866116e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Packages\n",
    "\n",
    "import transformers\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3551fa4d-754d-4aa2-a009-fbd82f03bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the PDF file\n",
    "pdf_file = open(\"RH-1-productfaq.pdf\", \"rb\")\n",
    "pdf_reader = PdfReader(pdf_file)\n",
    "\n",
    "# Loop through each page and extract text\n",
    "text = \"\"\n",
    "for page in pdf_reader.pages:\n",
    "    text += page.extract_text()\n",
    "\n",
    "# Close the PDF file\n",
    "pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd06d21-f443-4d32-8f9f-91982835a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the context\n",
    "text = re.sub(r'[^\\w\\s\\n]', '', text) # Remove punctuation\n",
    "text = text.lower() # Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c511ae14-ea8a-41bb-ac98-fcb8eee4707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'home products red hat openshift re   \\nred hat openshift\\nservice on aws\\nfrequently asked\\nquestions\\nget answers to common questions about red\\nhat openshift service on aws rosa\\xa0 learn\\nhow to quickly build deploy and manage\\nkubernetes applications on the industrys most\\ncomprehensive application platform in aws cloud\\ngeneral questions\\nwhat does red hat openshift service on aws include\\neach red hat openshift service on aws cluster comes with a fullymanaged\\ncontrol plane master nodes and application nodes installation management\\nmaintenance and upgrades are\\xa0 monitored by red hat site reliability engineers\\nsre with joint red hat and amazon support\\xa0 cluster services such as logging\\nmetrics monitoring are available as well\\nhow is red hat openshift service on aws different from red hat\\nopenshift container platform\\nred hat openshift service on aws delivers a turnkey application platform\\noptimized for performance scalability and security red hat openshift service\\non aws is hosted on amazon web serv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf31640-ff63-459e-b489-d847eac55450",
   "metadata": {},
   "source": [
    "Now, we will be using the text we have accessed to answer some questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfcfda68-9790-4ede-9365-ea7dfa98f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'\n",
    "\n",
    "quan_pipeline = pipeline(tokenizer=model_name, model=model_name, task='question-answering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169fa891-ff9a-422e-9395-ad555626c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=quan_pipeline(question=\"what is the purpose of this document?\",\n",
    "             context=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623e889b-4aba-4842-9ee9-748f599fd649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.11516688019037247,\n",
       " 'start': 21770,\n",
       " 'end': 21797,\n",
       " 'answer': 'subscribe to our newsletter'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5144dfa4-e58c-4e49-9bde-3e761a5f0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=quan_pipeline(question=\"Is Red Hat OpenShift Service on AWS available for purchase in all countries?\",\n",
    "             context=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b94a796e-266c-4ef8-afba-4f5ab4b59437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2048490196466446,\n",
       " 'start': 3796,\n",
       " 'end': 3874,\n",
       " 'answer': 'available for purchase in all countries where\\naws is commercially availablered'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f153d8-91dc-47b1-bd1d-735a5d6a57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=quan_pipeline(question=\"What is the maximum number of worker node that the cluster can support?\",\n",
    "             context=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e83076-20ee-4ef7-8be0-600a9cef51e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.8800130486488342, 'start': 21078, 'end': 21081, 'answer': '180'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f00608-63e2-4eb7-a3b7-b359f464ed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer=quan_pipeline(question=\"What is ROSA\",\n",
    "             context=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e8dc1a-e2b1-4bfc-8a17-c458e0700d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.3828146457672119,\n",
       " 'start': 11356,\n",
       " 'end': 11415,\n",
       " 'answer': 'an opinionated installation of openshift container platform'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68639d-ef7d-40b2-849a-ad2f97931d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27e5ac04-60d5-4033-ace1-628ea214f58d",
   "metadata": {},
   "source": [
    "# Abstractive QA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b693c4-e198-4c23-b61e-bcbd1b48966e",
   "metadata": {},
   "source": [
    "Abstractive QA systems, on the other hand, attempt to understand the meaning of a question and generate an answer that summarizes or rephrases the information present in the text. Unlike extractive QA systems, abstractive QA systems do not simply extract an answer, but generate a new answer that may not be present in the text. This approach requires a more sophisticated understanding of language and often uses techniques such as summarization, text generation, and natural language generation. Abstractive QA systems are designed to work well when the answer is not explicitly stated in the text but can be inferred from it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c1feb5-aaaf-47a8-80df-522f29e218d1",
   "metadata": {},
   "source": [
    "In this case, contexts are used as inputs (alongside the question) to a generative sequence-to-sequence (seq2seq) model. The model uses the question and context to generate the answer. Large transformer models store ‘representations’ of knowledge in their parameters. By passing relevant contexts and questions into the model, we hope that the model will use the context alongside its ‘stored knowledge’ to answer more abstract questions.\n",
    "\n",
    "The seq2seq model used is commonly BART or T5-based. In our case, we initialize a seq2seq pipeline using a BART model fine-tuned for abstractive QA — yjernite/bart_eli5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "500531c6-2b87-430a-8ac2-b0d84db6197b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'yjernite/bart_eli5'\n",
    "\n",
    "quan_pipeline = pipeline(tokenizer=model_name, model=model_name, task='text2text-generation') #seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009668aa-991c-4bd4-9feb-7da9e83c875d",
   "metadata": {},
   "source": [
    "Here is the actual text:\n",
    "\n",
    "\"\"\"\n",
    " What is the maximum number of worker nodes that a cluster can\n",
    "support?\n",
    "\n",
    "The maximum number of worker nodes is 180 per ROSA cluster. See here for\n",
    "limits and scalability considerations and more details on node counts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f448ec34-e378-45b1-bc78-6686d841e8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What is the maximum number of worker node that the cluster can support?\"\n",
    "context = text[-1000:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce56c3e8-0522-4aa5-8a32-23bb2ce4d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = quan_pipeline(f\"question: {query} ? context: {context}\",\n",
    "                               num_beams=4,\n",
    "                               do_sample=True,\n",
    "                               temperature=1.5,\n",
    "                               max_length=100) #Increasing the length\n",
    "\n",
    "generated_text = generated_text[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3e04a13-6b16-4d54-853f-772aacd3dfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The maximum number of worker nodes that a cluster can support is 180. See here for limits and scalability considerations and more details on node counts. See about autoscaling nodes on a cluster in the documentation for more details. The maximum number of worker nodes is 180 per rosa cluster. See here for limits and scalability considerations and more details on node counts. The maximum number of worker nodes is 180 per rosa cluster See here forlimits and scalability considerations and more details on'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c807b23-9d3b-4a6e-a8b3-ad90702171d1",
   "metadata": {},
   "source": [
    "Lets try another query, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be53476-1d35-4dab-983b-583e7cd29b9b",
   "metadata": {},
   "source": [
    "Here is the sample Q&A taken out from the FAQ doc:\n",
    "    \n",
    "\"\"\"\n",
    "How is Red Hat OpenShift Service on AWS different from Red Hat\n",
    "OpenShift Container Platform?\n",
    "\n",
    "Red Hat OpenShift Service on AWS delivers a turnkey application platform,\n",
    "optimized for performance, scalability, and security. Red Hat OpenShift Service\n",
    "on AWS is hosted on Amazon Web Services public cloud and jointly managed by\n",
    "Red Hat and AWS. Some options and administrative functions may be restricted\n",
    "or unavailable. A Red Hat OpenShift Container Platform subscription entitles you\n",
    "to host and manage the software on your infrastructure of choice.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9a1c198-aaaf-4234-b440-7618ca40cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'How is Red Hat OpenShift Service on AWS different from Red Hat OpenShift Container Platform?'\n",
    "\n",
    "context = text[:2000] # Here I am taking the context as initial 2000 characters from the text doc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84017cfb-e4f5-441f-a15f-f17ddff5e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = quan_pipeline(f\"question: {query} ? context: {context}\",\n",
    "                               num_beams=4,\n",
    "                               do_sample=True,\n",
    "                               temperature=1.5,\n",
    "                               max_length=100) #Increasing the length\n",
    "\n",
    "generated_text = generated_text[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "148ca929-f0ca-4a42-82f9-be4ac4e938d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Red Hat OpenShift Service on AWS is a full-managed, managed, managed service. There's a management team, there's people to monitor the cluster, there's someone to monitor the cluster, there's someone to review the cluster, etc. RHT OpenShift Cloud Platform is a full-managed service where you can build your own virtual machine on top of someone else's machine. There's nobody monitoring your cluster, nobody checking it. There's nobody to monitor your cluster, there\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d210452c-8ea2-49dc-93d8-9e73900f8907",
   "metadata": {},
   "source": [
    "Lets try another one, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ddb1437-e409-4bda-b036-4e3d3afcf12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What is the purpose of this document?'\n",
    "\n",
    "context = text[:3000] # Here I am taking the context as initial 2000 characters from the text doc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "608e4b14-d96a-4eef-a9df-532fc6b66121",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = quan_pipeline(f\"question: {query} ? context: {context}\",\n",
    "                               num_beams=4,\n",
    "                               do_sample=True,\n",
    "                               temperature=1.5,\n",
    "                               max_length=100) #Increasing the length\n",
    "\n",
    "generated_text = generated_text[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32b8176f-2b6e-47f7-a7f1-b0831f784d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" It's a manual for Redhat OpenShift. It's useful if you're planning on using Redhat in a large enterprise environment. I've never heard of it before, but after reading this manual I'm wondering what purpose it's for. It seems like it's a good idea, but I've never had a need to use it.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11b4757-2fa3-4b02-ac28-1cfd372f7bfa",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f1e2b-9535-4a8f-96fb-78d69ad4b52d",
   "metadata": {},
   "source": [
    "In this notebook, we tried to explore transformers models which would be efficient for creating a QA pipeline. In the first case, we tried to look into extractive QA, where the answer for the given query was searched from the context provided. In this case, the answers are short and sometimes does not make much sense. \n",
    "\n",
    "In the second case, we tried to build generative QA pipeline by training a seq2seq model, where for a given query and context. It will be able to generate text which might be close to the actual answer and also more like human written sentence.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
